project:
  id: %PROJECT_ID%
  region: %REGION%
  use_free_tier: false  # Enable free tier resource limits

features:
  enabled_services:
    cloud_api: false      # Cloud Run API and services
    cloud_functions: true # Cloud Functions API and services
    cloud_build: true    # Cloud Build API and triggers
    storage: true        # Cloud Storage API and buckets
    pubsub: true        # Pub/Sub API and topics
    scheduler: true     # Cloud Scheduler API and jobs
    firestore: true     # Firestore API
    secrets: true       # Secret Manager API and secrets
    bigquery: true      # BigQuery API for ML data warehouse
    ml: true            # Machine Learning features (Vertex AI, etc.)
    aiplatform: true    # Vertex AI API for model training/deployment

gcp:
  project_id: %PROJECT_ID%
  region: %REGION%
  service_account_key_path: "credentials/service-account-key.json"

ml:
  inference:
    mode: "cloud_function"  # Options: cloud_function | vertex_ai | local
    # If mode is cloud_function, provide the HTTPS trigger URL
    function_url: ""  # e.g., https://us-central1-%PROJECT_ID%.cloudfunctions.net/ml-inference-function
    function_name: "ml-inference-function"
    timeout_seconds: 15
  local_model_path: ""  # Optional: path to a local .joblib for local testing

pubsub:
  topics:
    transactions: "scheduled-transactions"  # Name of the transactions topic

scheduler:
  jobs:
    transaction_processor:
      name: "process-scheduled-transactions"
      description: "Triggers transaction processing on a schedule"
  transaction_sync:
    schedule: "*/10 * * * *"  # Run every 10 minutes
    timezone: "America/Chicago"
    retry_count: 3
    retry_interval: 300  # 5 minutes between retry attempts
    timeout: 540  # Maximum time a single Cloud Function execution can run

cloud_build:
  triggers:
    auto_deploy:
      name: "auto-deploy-trigger"
      description: "Trigger auto-deployment on main branch pushes"
      github:
        owner: "%GITHUB_USERNAME%"
        repository: "%REPOSITORY_NAME%"
        branch: "^main$"
  secrets:
    service_account_key: "service-account-key"

data:
  bucket_name: "%PROJECT_ID%-data"
  sync_interval: 3600  # seconds
  ml_artifacts_bucket: "%PROJECT_ID%-ml-artifacts"
  credentials:
    secret_pattern: "gmail-credentials-%USER_ID%-%EMAIL%"
    default_secret: "google-credentials-default"
    firebase_secret: "firebase-credentials-default"
    gmail_secret: "gmail-credentials"
  user_batch_size: 10  # Process users in batches
  transaction_batch_size: 100  # Transactions per batch
  transaction:
    batch_size: 500
    status_values:
      - pending
      - processed
      - failed
    required_fields:
      - id
      - date
      - description
      - amount
      - account_id
      - user_id

storage:
  buckets:
    data: "%PROJECT_ID%-data"
    ml_artifacts: "%PROJECT_ID%-ml-artifacts"
    functions: "%PROJECT_ID%-functions"
  location: %REGION%

model:
  training_file: transaction_categorizations.xlsx
  model_name: transaction_categorization_model

cloud_run:
  service_name: transaction-api
  min_instances: 1
  max_instances: 10
  cpu_utilization: 0.65
  instance_class: F1
  container_image: "gcr.io/%PROJECT_ID%/transaction-api:latest"

cloud_function:
  name: transaction-processor
  runtime: python310
  timeout: 540  # seconds
  memory: 512  # MB - configurable memory for transaction processor
  entry_point: process_transactions
  source_path: "gs://%PROJECT_ID%-functions/function-code.zip"
  environment_variables:
    GOOGLE_CLOUD_PROJECT: "%PROJECT_ID%"
    CONFIG_PATH: config.yaml
  exclude_patterns:
    - sample_code/
    - tests/
    - scripts/
    - .vscode/
    - .coverage
    - .pytest_cache/
    - htmlcov/
    - "*.egg-info/"
    - build/
    - dist/
    - .mypy_cache/
    - .hypothesis/
    - .tox/
    - docs/
    - notebooks/

# Data Export Function for ML Pipeline
data_export_function:
  name: data-export-function
  runtime: python310
  timeout: 540  # 9 minutes
  entry_point: export_training_data
  source_path: "gs://%PROJECT_ID%-functions/data-export-function.zip"
  memory: 512  # MB
  schedule: "0 2 * * 0"  # Weekly on Sunday at 2 AM
  environment_variables:
    PROJECT_ID: "%PROJECT_ID%"
    GOOGLE_CLOUD_PROJECT: "%PROJECT_ID%"
    LOG_LEVEL: "INFO"

# Model Retraining Function
model_retraining_function:
  name: model-retraining-function
  runtime: python310
  timeout: 540  # 9 minutes for training
  entry_point: trigger_model_retraining
  source_path: "gs://%PROJECT_ID%-functions/model-retraining-function.zip"
  memory: 2048  # MB
  schedule: "0 2 * * 0"  # Weekly at 2 AM on Sundays
  environment_variables:
    PROJECT_ID: "%PROJECT_ID%"
    GOOGLE_CLOUD_PROJECT: "%PROJECT_ID%"
    LOG_LEVEL: "INFO"
    MIN_FEEDBACK_COUNT: "5"
    DAYS_LOOKBACK: "14"

# Model Performance Checker Function
model_performance_checker:
  name: model-performance-checker
  runtime: python310
  timeout: 60
  entry_point: check_model_performance
  source_path: "gs://%PROJECT_ID%-functions/model-performance-checker.zip"
  memory: 512  # MB
  schedule: "0 2 * * 1" #Every Monday # "0 */6 * * *"  # Every 6 hours
  environment_variables:
    PROJECT_ID: "%PROJECT_ID%"
    GOOGLE_CLOUD_PROJECT: "%PROJECT_ID%"
    LOG_LEVEL: "INFO"

auth:
  # Gmail IMAP settings
  gmail:
    service_url: "imap.gmail.com"
    port: 993
    scopes:
      - "https://www.googleapis.com/auth/gmail.readonly"
      - "https://www.googleapis.com/auth/gmail.modify"
    token_uri: "https://oauth2.googleapis.com/token"
    email_to_account:
      "%EMAIL%": "%ACCOUNT_NAME%"
    accounts:
      %ACCOUNT_NAME%:
        user_id: "%USER_ID%"
        description: "%USER_NAME%"
        credentials_file: "credentials/gmail_oauth_credentials_%ACCOUNT_NAME%.json"

  # Firebase settings
  firebase:
    service_url: "https://identitytoolkit.googleapis.com/v1/accounts"

logging:
  level: "INFO"  # INFO|DEBUG|WARNING
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

testing:
  run_after_deployment: true  # Whether to run tests after deployment
  run_all_tests: false  # Whether to run all available tests
  wait_time: 10  # Seconds to wait for function to be ready before testing
  test_order:  # Defines the logical order of test execution
    - unit_tests  # Run unit tests before deployment
    - package_tests  # Run package tests before deployment
    - ml_tests  # Run ML tests before deployment (if ML enabled)
  components:  # Which components to test
    unit_tests: true  # Run unit tests
    package_tests: true  # Run package tests
    config_tests: false  # Skip config tests
    integration_tests: false  # Skip integration tests
    ml_tests: true  # Run ML tests (only if ML is enabled)
    function: true  # Test deployed function
    scheduler: false  # Skip scheduler tests
    pubsub: false  # Skip pub/sub tests
    http: false  # Skip HTTP tests
    pubsub_trigger: false  # Skip pub/sub trigger tests
  test_paths:  # Paths to test files
    unit_tests:  # Unit tests to run before deployment
      - tests/test_gmail_integration.py
      - tests/test_transaction_parse.py
    package_tests:  # Package tests to run before deployment
      - scripts/test_deployment_package.py
    ml_tests:  # ML tests to run before deployment
      - scripts/test_trained_models_locally.py
    post_deployment:  # Tests to run after deployment
      - scripts/test_function.py 